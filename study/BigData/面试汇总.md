## Flink常见面试题

### 一、应用架构

问题：公司怎么提交的实时任务，有多少Job Manager、Task Manager？

解答：

1. 我们使用yarn session模式提交任务：另一种方式是每次都会创建一个新的Flink集群，为每一个job提供资源，任务之间互相独立，互不影响，方便管理。任务执行完成之后创建的集群也会消失。
2. 集群默认只有一个Job Manager。但为了防止单点故障，我们配置了高可用。对于standlone模式，我们公司一般配置一个主Job Manager，两个备用Job Manager，然后结合Zookeeper的使用，来达到高可用；对于yarn模式，yarn在Job Manager故障会自动进行重启，所以只需要一个，我们配置的最大重启次数是10次。

### 二、压测和监控

问题：怎么做压力测试和监控？

解答：我们一般碰到的压力来自以下几个方面：

1，产生数据流的速度如果过快，而下游的算子消费不过来，会产生背压。背压的监控可以使用Flink Web UI（localhost:8081）来可视化监控Metrics，一旦报警就能知道。一般情况下背压问题的产生可能是由于sink这个操作符没有优化好，做一下优化就可以了。比如如果是写入ElasticSearch，那么可以改成批量写入，可以调大ElasticSearch队列的大小等等策略。

2，设置watermark的最大延时时间这个参数，如果设置的过大，可能会造成内存的压力。可以设置最大延迟时间小一些，然后把迟到元素发送到侧输出流中去。晚一点更新结果。或者使用类似于RocksDB这样的状态后端，RocksDB会开辟堆外存储空间，但IO速度会变慢，需要权衡。

3，还有就是滑动窗口的长度如果过长，而滑动距离很短的话，Flink的性能会下降的很厉害。我们主要通过时间分片的方法，将每个元素只存入一个“重叠窗口”，这样就可以减少窗口处理中状态的写入。

### 三、为什么用Flink

问题：为什么使用Flink代替Spark？

解答：主要考虑的事Flink的低延迟、高吞吐量和对流式数据应用场景更好的支持；另外，Flink可以很好地处理乱序数据，而且可以保证extactly-once的状态一致性。

### 四、checkpoint的存储

问题：Flink的checkpoint存放在哪里？

解答：可以是内存，文件系统、RocksDB。

### 五、exactly-once的保证

问题：如果下级存储不支持事务，Flink怎么保证exactly-once？

解答：端到端的exactly-once对sink要求比较高。具体实现主要由幂等写入和事务型写入两种方式。幂等写入的场景依赖于业务逻辑，更常见的是用事务性写入。而事务性写入又有预写日志（WAL）和两阶段提交（2PC）两种方式。

如果外部系统不支持事务，那么可以用预写日志的方式，把结果当成状态保存，然后在收到checkpoint完成的通知时，一次性写入sink系统。

### 六、状态机制

问题：Flink的状态机制

解答：Flink内置的很多算子，包括源source，数据存储sink都是有状态的。在Flink中，状态始终与特定算子相关联。Flink会以checkpoint的形式对各个任务的状态进行快照，用于保证故障恢复时的状态一致性。Flink通过状态后端来管理状态和checkpoint的存储，状态后端可以有不同的配置选择。

### 七、海量key去重

问题：怎么去重？考虑一个实时场景：双十一场景，滑动窗口长度为1小时，滑动距离为10s，亿级用户，怎么计算UV？

解答：使用类似于scala的set数据结构或者redis的set显然是不行的，因为可能有上亿个key，内存放不下。所以可以考虑使用布隆过滤器(Bloom Filter)来去重。

### 八、checkpoint与spark比较

问题：Flink的checkpoint机制对比spark有什么不同和优势？

解答：spark streaming的checkpoint仅仅是针对driver的故障恢复做了数据和元数据的checkpoint。而flink的checkpoint机制要复杂了很多，它采用的是轻量级的分布式快照，实现每个算子的快照，及流动中的数据的快照。

### 九、watermark机制

问题：请详细解释一下Flink的Watermark机制

解答：Watermark本质是Flink中衡量EventTime进展的一个机制，主要用来处理乱序数据。

### 十、exactly-once如何实现

问题：Flink中exactly-once语义是如何实现的，状态是如何存储的？

解答：Flink依靠checkpoint机制来实现exactly-once语义，如果要实现端到端的exactly-once，还需要外部source和sink满足一定的条件。状态的存储通过状态后端来管理，Flink中可以配置不同的状态后端。

### 十一、CEP

问题：Flink CEP编程中当状态没有到达的时候会将数据保存在哪里？

解答：在流式处理中，CEP当然是要支持EventTime的，那么相对应的也要支持数据的迟到现象，也就是watermark的处理逻辑。CEP对未匹配成功的事件序列的处理，和迟到数据是类似的。在Flink CEP的处理逻辑中，状态没有满足的和迟到的数据，都会存储在一个Map数据结构中，也就是说，如果我们限定判断事件序列的时长为5分钟，那么内存中就会存储5分钟的数据，也是对内存的极大损伤之一

### 十二、三种时间语义

问题：Flink的三种时间语义是什么，应用场景？

解答：

1. Event Time：这是实际应用中最常见的时间语义。
2. Processing Time：没有事件时间的情况下，或者对实时性要求超高的情况下。
3. Ingestion Time：存在多个Source Operator的情况下，每个Source Operator可以使用自己本地系统时钟指派Ingestion Time。后续基于时间相关的各种操作，都会使用数据记录中的Ingestion Time。

### 十三、数据高峰的处理

问题：Flink程序在面对数据高峰期时如何处理？

解答：使用大容量的Kafka把数据先放到消息队列里面作为数据源，再使用Flink进行消费，不过这样会影响到一点实时性。

