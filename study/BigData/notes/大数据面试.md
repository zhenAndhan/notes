## Linux&Shell

```shell
1、常用的高级命令（5个）
	ps -ef、df -h 	top、	iotop	rpm -ivh、netstat
2、查看进程、查看端口号、查看磁盘使用情况
	ps -ef top 、 netstat 、	df -h
3、写过哪些脚本
	1）启动停止脚本、分发
		#!/bin/bash

		case $1 in
		"start"){
			for i in hadoop102 hadoop103 hadoop104
			do
				ssh $i 	"启动命令，用绝对路径"
			done
		};;
		"stop"){
			for i in hadoop102 hadoop103 hadoop104
			do
				ssh $i 	"停止命令，用绝对路径"
			done
		};;
		esac


	2）数仓层级内部导入
		ods => dwd => dws => dwt => ads

		#!/bin/bash

		#定义变量	APP

		#获取时间	

		#sql="具体的sql;（先写一天的，然后在表名字前面加上$APP，将时间换成$do_date）"
		
		# 执行sql

	3）数仓与MySQL之间的导入导出
	
	
4、Shell	常用工具
	awk		sed		sort	cut		

5、单引号和双引号的区别
	1）单引号：'$do_date'	在引号内部的变量不能解析里面变量对应的值
	2）双引号："$do_date"	在引号内部，能取出变量的值
	3）嵌套：看谁在最外层		"'$do_date'" 能	'"$do_date"' 不能
```

## Hadoop
```shell
1、入门
	1）常用端口号
		3.x
			HDFS	历史服务器	MapReduce	客户端
			9870	19888		8088		9000/8020
		2.x
			50070	

	2）安装配置文件
		2.x
			core-site.xml	hdfs-site.xml	yarn-site.xml	mapred-site.xml	slaves
		3.x
			core-site.xml	hdfs-site.xml	yarn-site.xml	mapred-site.xml	workers
2、HDFS
	1）读写流程	笔试题	找兄弟

	2）小文件问题
		（1）危害
			占namenode元数据内存
				（不管文件多小，都要占150字节）
			128g内存的namenode能存储多少个文件块
				128g * 1024m * 1024 kb * 1024字节 / 150字节 => 约等于9亿

			增加切片，进而影响增加maptask个数（1g），增加计算内存

		（2）优化手段
			har归档；
			CombineTextInputformat	改变切片
			JVM
				开始		2s

					干活		2s

					干活		2s

				结束		2s
		（3）HDFS有几个副本
			3个
		（4）HDFS块大小
			2.x	3.x	默认块	128m
					本地模式	32m

			1.x 	块大小	64m

			hive的块大小：		256m
			在大厂企业块大小：	256m

			块大小，取决于服务器之间的传输速率

3、MapReduce
	shuffle及其优化

	map方法之后，reduce方法之前。打乱重新组合的过程

4、Yarn
	1）FIFO、容量调度器、公平调度器
	2）默认哪个调度器：
		Apache	默认容量
		CDH		默认公平
	3）FIFO调度器：
		支持单队列、先进先出、同一时间只有一个任务执行。
		并发度非常低，在企业里面不会使用
	4）容量调度器：
		支持多队列，由多个FIFO调度器组成，优先满足，先进入的任务
		并发度一般
	5）公平调度器
		支持多队列，每个任务都公平享有资源，并发度最高
	6）在企业里面怎么选择
		如果电脑服务器性能比较好，对并发度要求比较高，选择公平调度器
		（上市公司、大厂）

		如果电脑服务器性能比较差，对并发度要求不是特别高，选择容量调度器
		（中小型公司）
	7）在企业开发时，如何创建队列
		容量调度器默认就一个default队列；
		按照执行任务的框架创建：hive、spark、flink
		按照业务模块创建（较多）：登录注册模块、订单、物流

		降级使用

	8）YARN的工作机制


5、数据倾斜
	解决数据倾斜的办法
	1）提前在map进行combine，减小传输的数据量
	2）导致数据倾斜的key大量分布在不同的mapper---局部聚合+全局聚合
```

## Zookeeper

```
1）安装台数？
	奇数
	10台服务器安装多少台？	3台
	20台服务器安装多少台？	5台
	50台服务器安装多少台？	7台
	100台服务器安装多少台？	11台

	台数越多，提高数据可靠性；增加了通信延时，降低了效率

2）选举机制
	半数机制		

3）常用命令
	ls get create  delete
```





## Flume（三件事）

```
1、组成（source、channel、sink）
	1）taildir source
		（1）为什么？断电续传、多目录
		（2）哪个版本产生的？ Apache 1.7 		cdh 1.6
		（3）如果没有taildir source，怎么实现断点续传？
				自定义source（Apache 1.7源码）
		（4）taildir source，会有什么影响？
			数据不会丢，有可能重复
		（5）数据重复了怎么解决
			不处理	提升传输效率

			处理
				自身：	采用事务（自定义source）
				下一级处理：hive的dwd 	sparkStreaming 	redis
						group by 或者开窗取第一条
		（6）是否支持递归遍历文件夹，读取数据
			自定义source 	递归遍历文件夹 + taildir读取文件

	2）channel
		（1）filechannel		基于磁盘		可靠性高		传输效率低
				100万个event	
		（2）memorychannel	基于内存 	可靠性低 	传输效率高
				100个event	
		（3）Kafkachannel	数据存储在Kafka里面	基于磁盘的	可靠性高
							Kafkachannel传输性能高于memorychannel + kafkasink
						kafkachannel是Apache1.6产生的，但是当时没火
						头信息+内容 => 需要后续清洗	提供了参数，很遗憾，没起作用。

						Apache1.7之后，问题解决，火了
		（4）在企业里面如何选择
			如果下一级是kafka，优先选择Kafkachannel
			如果不是：
					如果是对可靠性要求较高，比如金融行业，或者跟钱相关数据，选择filechannel
					如果是普通的日志，对可靠性要求不高，对传输效率要求较高，选择memorychannel
	3）hdfs sink
		小文件
			文件大小（128m）、文件时间（1-2小时）、event个数（0）


2、三个器（拦截器、选择器、监控器）
	1）拦截器：
		ETL拦截器		判断json的完整性；	{}

		（1）事件拦截器	event 	start
			event（商品点击、商品列表、商品详情
				广告
				故障
				点赞、评论、收藏
				后台活跃、通知
			）
		（2）自定义拦截器步骤：定义类，实现interceptor接口，重写里面4个方法
				初始化、关闭资源、单event处理、多event处理	builder

			打包 =>  上传到flume/lib 在配置文件中关联拦截器
				全类名 $builder

		（3）不用拦截器行不行
			可以 => 在hive的dwd层解析		或者sparkStreaming内部解析

	2）选择器
		replicating（默认）		把数据发往下一级所有通道
		multiplexing 			把数据选择性发送到指定通道

	3）监控器
		Ganglia

		尝试提交的次数，远远大于最终提交成功的次数。需要优化flume

		自身：flume		增加内存 	flume-env.sh

		找兄弟：增加flume	
			6.18 	11.11
			日志服务器配置（阿里云）：	16g/32g		SpingBoot	flume


3、优化
	1）filechannel 	能多磁盘配置多磁盘，能提高吞吐量
	2）hdfs sink
		小文件
			文件大小（128m）、文件时间（1-2小时）、event个数（0）
	3）监控		
		自身：flume		增加内存 	flume-env.sh

		找兄弟：增加flume	

4、挂了怎么办？
	如果是memorychannel		有可能丢数据		100个event

	如果是taildirsource		不会丢数据，但是有可能有重复数据
```



## kafka 23件事

### Kafka为什么能高效的读写数据？

```
1)分布式集群，采用分区技术
2)顺序写磁盘
3)零拷贝
```





```

1、基本信息
	1）组成
	2）安装多少台		
				2（生产者峰值生产速率 * 副本/100）+ 1 = 3
				2 * (x * 2 / 100) + 1 = 3
					x = 100 		5台Kafka
	3）压测：生产者峰值生产速率
	4）副本：默认1 	2-3个副本
		副本越多：可靠性越高、		增加了磁盘IO，效率低下
	5）数据量问题
		100万日活	每个人100条		100万*100=1亿
		一条日志：0.5k~2k => 1k

		每天数据量：1亿 * 1k = 100g

		平均速度：1亿条/(24 * 3600s) = 1150条/s
			1150条*1k/s = 1m

		峰值速度：
			7-10左右		1150条/s * 20/s = 2万条

			20m/s
	6）kafka里面数据保存多久
		默认：7天 => 3天

	7）磁盘预留多大
		100g * 2副本 * 3天 / 0.7 = 

	8）kafka做不做监控？
		kafka manager	kafkaEagle	开源

	9）分区：
		先设置一个分区；
		生产者峰值生产速率 tp、消费者消费的峰值速率tc
		自己要有一个kafka吞吐量的预期		t

		分区数 = t / min(tp,tc)
		t=100m/s 	tp = 40m/s 		tc = 50m/s

		100 / 40 = 2.5 = 3个分区

		3-10个分区
	10）分区分配策略
		Range（默认）
			10个分区 	3个消费者线程

			0 1 2 3 	容易产生数据倾斜
			4 5 6
			7 8 9

		RoundRobin
			全部hash随机打散，再轮询
	11）ISR
		主要解决leader挂了，谁当老大；在ISR队列里面的都有机会
		旧版本：延迟时间、延迟条数；
		新版本：延迟时间

2、挂了
	短时间 	会存储在flume channel里面
	长时间	日志服务器保存30天数据

3、丢了
	ack
	0 		发送过来就不管了			可靠性最差 		传输效率最高
	1 		leader应答				可靠性一般		传输效率一般
	-1 		leader+follower共同应答  可靠性最高		传输效率最低

	在生产环境：
		0 肯定不选
		1 一般传输的事普通的日志，对可靠性要求不是特别高。
		-1传输的是钱相关的，或者金融企业，对可靠性要求高， 

4、重复了
		自身：幂等性、事务、ack = -1 				用的比较少： 		更追求效率

		找兄弟：hive的dwd、sparkStreaming、redis	用的比较多

5、积压了
	1）增加分区	同时增加下一级消费者的CPU核数

	2）增加下一级消费者消费速度
		flume 	sparkStreaming 	batchsize 	1000event/s => 2000event/s

6、优化
	1)Broker参数配置
		（1）日志保留策略配置
		（2）Replica相关配置
		（3）网络通信延时
	2）Producer优化
	3）Kafka内存调整

7、杂七杂八
	1）Kafka高效读写数据
		（1）kafka本身就是集群、可以设置分区
		（2）采用顺序读写；600m/s 		随机读写100m/s
		（3）采用了零拷贝技术
```

### kafka消息数据积压，Kafka消费能力不足怎么处理？

```
1)如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）
2)如果是下游的数据处理不及时：提高每批次拉取的数量。批量拉取数据过少(拉取数据/处理时间<生产速度)，使处理的数据小于生产的数据，也会造成数据积压
```






## hive

```sql
1、hive的组成
	hive的运行原理：
		1)用户提交查询任务给Driver。
		2)Antlr解析器将SQL转化为抽象语法树AST Tree
		3)遍历AST Tree，抽出基本单元QueryBlock
		4)遍历QueryBlock，翻译为执行操作树OperatorTree
		5)逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量。
		6)遍历OperatorTree，翻译为MapReduce任务
		7)物理层优化器进行MapReduce任务的变换，生成最终的执行计划
		8)执行计划，返回结果。
	

2、与mysql区别
				hive 			mysql
	数据量 		大 				小
	速度 		大数据=>快 		小数据=>块
				查询				增删改查

3、内部表和外部表(external)区别
	元数据、原始数据

	内部表删除数据：删除元数据和原始数据
	外部表删除数据：删除元数据

	什么时候用内部表？	什么时候用外部表？
	绝大多数表都是外部表；
	只有自己使用的临时表是内部表；

4、4个by
	order by 	全局排序 => 容易发生数据倾斜
	sort by 	排序
	d by 		分区  sort + d  => 分区内排序
	c by 	sort + d 	字段相同时，可以用c by	

5、系统函数
	时间相关
		日(date_add、date_sub)、周(next_day)、月(date_format、lastday)
	解析json(get_json_object)

6、自定义函数
		UDF/UDTF
	1）自定义UDF解决 		解析公共字段；
	2）自定义UDTF，解析了事件字段；
	3）不用自定义函数行不行？
		可以不用：	那你为什么不用呢？	方便定位bug
	4）自定义UDF步骤
		定义类 继承UDF，重写evaluate方法；
	5）自定义UDTF步骤
		定义类 继承UDTF，重写3个方法，
		分别是初始化（定义返回值的名称和类型）、process、关闭资源

	打包 => 上传到HDFS路径 => 在hive的客户端创建永久函数		

7、窗口函数
	rank 	over 	topn

8、优化
	1）mapjoin默认打开不要关闭
	2）行列过滤： 	join + where                =>  where + join
					1亿 join 1亿 条 where 1条
	3）创建分区表（天）
	4）小文件相关处理
		（1）CombinehiveInputFormat => 减少切片的个数，减少maptask个数
		（2）JVM重用
		（3）merge 如果是maponly任务，默认打开
			执行完任务后，会产生大量小文件，默认会帮你开启一个job，将小于16m的文件，合并到256m
			如果是mapreduce任务，需要将该功能开启。
	5）压缩
	6）列式存储
		id	name 	age
		1 	zs		18
		2 	lisi	19

		行：1 zs	18 2 	lisi 	19
		列：1 2 	zs lisi 18 		19
	7）替换引擎
		mr 			基于磁盘 		可靠性高 	效率低 		数据量大	，计算时间比较长 	周、月、年
		tez			基于内存			可靠性差 	效率高 		临时调试代码使用，即席查询
		spark 		基于内存+磁盘 	可靠性一般 	效率居中 	每天的定时任务	

	8）在map端提前开启combiner（不影响最终业务逻辑）

	9）合理设置map个数、reduce个数
		max(0,min(块大小，Long的最大值))
		128m数据 => 1g

9、数据倾斜
	1）不同数据类型关联会产生数据倾斜
		解决方式：转换成相同类型
	2）控制空值分布

	3）解决数据倾斜的方法？
		（1）group by
		（2）mapjoin
		（3）开启数据倾斜时负载均衡

10、杂七杂八
	Mysql元数据备份
		Mysql基于Keepalived实现HA
	union和union all的区别
		union 		去重 	效率低
		union all 	不去重	效率高
```




## Sqoop

```
1、Sqoop参数
	策略：	全量导入
			增量导入
			新增及变化导入

2、Sqoop在开发过程中遇到过哪些问题？
	1）空值问题
		mysql			hive
		null			/N
				转换
	2）数据一致性问题
		hive	=>	mysql
		4个map
		2个map成功，2个失败。
			指标可以没有，但是不能错。	做决策提供数据支撑的
		--stageing-table
		mysql临时表	事务导入到正式表
	
3、Sqoop每天导入的数据
	100万日活	10万订单		10条 	1条日志1k  => 1g

	1g

	每天导入订单多少数据？	订单详情多少数据？	登录注册多少？	物流多少？

	java后台一共导过来多少业务表？		30张
	1g/30张=34m		2-3倍

	用户行为：100g	10张表  => 1张表10g		2-3倍
	实时项目每天处理多少条数据？业务数据读了哪些表（）用户行为（）

4、Sqoop数据导出的时候一次执行多长时间

	0:30开始执行		40-50分钟左右	618/11.11 		1个小时以上
		跟服务器性能有关系；

5、Sqoop在导入数据的时候数据倾斜
	1g  => 没有发生过；

	全部数据都是业务数据。数据量相对会大一些，有可能导致数据倾斜；
```



## HBase

HBase是一个分布式、海量存储、快速响应的非关系型数据库。

```
写数据
1.客户端从zk中获取mate表位置，到对应regionServer上获取该表，或直接从缓存中读取该表。
2.客户端从mate表中获取要写的数据存放的region和所在的regionServer。
3.客户端给数据设置版本(默认当前时间)，往该regionServer的Hlog上写日志数据
	客户端同时往该regionServer的memstore上写入数据。
	memstore溢写到磁盘，溢写的小文件达到阀值数量是会合并成一个storefile
	region体积达到阀值时拆分成两个region
	其Hmaster负责均衡负载，拆分规则为保留连 续行键，根据前缀判断。
写原子性
	写操作必须保证Hlog和memstore都写入完成才会返回成功，而且使用读写行锁保证一次对行写入期间其他读写请求会阻塞等待。
	
读数据
1.客户端从zk中获取mate表位置，到对应regionServer上获取该表，或直接从缓存中读取该表。
2.客户端从mate表中获取行键所在的region位置。
3.先从memstore读取，再从blockcache读取，最后才找到hfile中查找，查找hfile前先用布隆过滤器筛选出可能存在该行键的hfile，从hfile读取到的数据会复制一份到blockcache中。
```





## Azkaban

```
1、业务相关：
	每天跑多少指标？
	平时100个左右	搞活动时指标会多一些？
2、在用Azkaban过程中遇到过问题吗？	怎么解决 	3.8.4	
	0:30开始 	8点
```



## 数仓项目

```
1、提高自信
	数据仓库的输入数据源和输出系统分别是什么？
		输入系统：埋点产生的用户行为数据，JavaEE后台产生的业务数据、个别公司的爬虫数据
		输出系统：报表系统、用户画像系统、推荐系统

2、框架版本选型
	Apache
	CDH
	HDP

3、

每天日活50w		设计一套大数据解决方案

入职：0-1公司

数据在哪里？有哪几种数据
用户行为数据：	文件 	问数据量大概多少
业务数据：	mysql 		问数据量


预算大概多少？

算多少指标？

离线、实时的（性能要求）	
```



## 数仓项目--分层

```
1、ODS层
	1）保持数据原貌，不做任何修改。		数据备份
	2）采用压缩	LZO => 减少磁盘空间	100g => 10g
	3）创建分区表：  => 防止后续计算时的全表扫描

2、DWD层
	1）数据清洗
		（1）解析数据
		（2）核心字段不能为空
		（3）过期数据清除
		（4）重复数据，进行过滤
	2）清洗掉多少条数据算干净的
		1万条清洗1条
	3）清洗工具
		hive sql、	spark sql、	python、	Kettle、	MR
	4）数据脱敏（身份证、手机号）
	5）采用压缩 => 减少磁盘空间
	6）创建分区表 => 防止后续计算时的全表扫描
	7）采用列式存储 => 增加查询速度
	8）维度退化

	9）建模
		（1）建模工具：
				EZMDL
		（2）建模过程：
				选择业务过程->声明粒度->确认维度->确定事实

				选择业务过程
					关心的事实表（下单、支付、点赞、收藏）
					中小型公司：选择所有业务过程
					大型公司：3000张表

				声明粒度
					一行信息表示声明含义：1次、1天、1周、1个月
					zhangsan	下单 	10块钱
					声明最小粒度（1次）
					（不要做聚合操作就可以）

				确认维度
					时间、地区、用户、商品、活动、优惠券

					维度退化（维度建模当中的星型模型，让事实表周围只有一级维度）

					商品表、商品SPU表、商品SKU表、三级分类、二级分类、一级分类 => 商品表
					省份+地区表 => 地区表
					时间表、假期表 => 时间表
					活动表+活动规则表 => 活动表

				确定事实
					确定事实表的度量值（次数、件数、个数、金额）
					度量值的特点就是可以累加

3、DWS层
	字段怎么来的？
	站在维度表的角度去看待事实，主要看的是事实的度量值。

4、DWT层
	站在维度表的角度去看待事实，我们主要关心事实表的度量值（累加值、累积一段时间的值）和行为的开始时间和结束时间

5、ADS层
	有多少指标？
	平时100个左右 活动时200个左右


​	
留 	1日留存、 2/3 	周留存、月留存
转 	商品详情 => 购物车 => 下单 => 支付
G 	每日GMV多少
复 	哪种商品复购率最高，大概是多少
活 	日活、周活、月活、年活 => 总人数

电商常识


6、即席查询数据仓库
	druid（clickhouse）			批处理/纯实时流处理
		横坐标：按时间预聚合
		纵轴采用：列式存储；采用了压缩
	Kylin
		预计算	hbase	速度很快
	presto		Apache框架选择presto
		支持的数据源非常多

	impala		CDH框架选择impala
		impala性能略优于presto

	spark
		每天的定时任务
	es
		没有大数据公司	ELK（大数据采集、查询、展示）
		用户画像


测试：
	sum(a,b)
	a = 1 到 100
	b = 1 到 100

	边界值	a => 1 100 -1 101

	等价类： a = 20 		80 		50

	测试用例：
		（1）针对sum函数进行测试，输入a=1，b=1 期望返回值2
		针对代码1.0 版本 测试结果发现：返回值为1 => 和预期结果不一样

		=> 开发人员（解释； 是一个问题）=> 升级版本1.1 	解决了该问题
		=> 测试人员在测试	 => 1.1ok => 测试经理关闭bug。
	开发时间1-2周 => 测试时间是开发时间两倍（配着）

	1:2


	瀑布式开发（V型开发）
		3-5年
		需求分析		（200）								需求测试
			系统总体设计								系统集成测试
				软件概要设计（类）				集成测试
					软件详细设计（方法）		单元测试
						代码编写			代码走查


	敏捷开发（小步快跑）
		需求分析10个
		代码编写
		测试
		需求分析10个
		代码编写
		测试

项目中遇到的问题怎么解决的
	Shell中flume停止脚本
	hadoop宕机
	hadoop解决数据倾斜方法
	集群资源分配参数------hadoop优化
	HDFS小文件处理

	flume挂掉
	flume优化

	Kafka挂了
	Kafka丢失
	Kafka优化
	Kafka单条日志传输大小

	自定义UDF、UDTF函数
	Hive优化
	Hive解决数据倾斜方法
	7天内连续3次活跃

	Sqoop空值、一致性、数据倾斜

	Azkaban任务挂了怎么办？
	Azkaban故障报警
```



## Redis

```markdown
缓存穿透、缓存雪崩、缓存击穿


## 哨兵模式
主从复制中反客为主的自动版，如果主机Down掉，哨兵会从从机中选择一台作为主机，并将它设置为其他从机的主机，而且如果原来的主机再次启动的话也会成为从机。

## 数据类型
String	字符串
list	可以重复的集合
set		不可以重复的集合
hash	类似于Map<String,String>
zset（sorted set）	带分数的set

## 持久化
1) RDB持久化：
	1. 在指定的时间间隔内持久化
	2. 服务shutdown会自动持久化
	3. 输入bgsave也会持久化
2) AOF：以日志形式记录每个更新操作
	Redis重新启动时读取这个文件，重新执行新建、修改数据的命令恢复数据。
	保存策略：
		推荐(并且也是默认)的措施为每秒持久化一次，这种策略可以兼顾速度和安全性。
	缺点：
		1. 比起RDB占用更多的磁盘空间
		2. 恢复备份速度要慢
		3. 每次读写都同步的话，有一定的性能压力
		4. 存在个别Bug，造成恢复不能
	选择策略：
		官方推荐：如果对数据不敏感，可以选单独用RDB；不建议单独用AOF，因为可能出现Bug；如果只是做纯内存缓存，可以都不用。
		
## 悲观锁
执行操作前假设当前的操作肯定(或有很大的几率)会被打断(悲观)。基于这个假设，我们在做操作之前就会把先管资源锁定，不允许自己执行期间有其他操作干扰。

## 乐观锁
执行操作前假设当前操作不会被打断(乐观)。基于这个假设，我们在做 操作前不会锁定资源，万一发生了其他操作的干扰，那么本次操作将被放弃。Redis使用的就是乐观锁。
		
```



## Spark

```
1.Spark解决什么问题？
    回顾：Hadoop主要解决，海量数据的存储和海量数据的分析计算。
    Spark主要解决海量数据的分析计算。

2.Spark的运行机制
    1)Local：运行在一台机器上。
    2)Standalone：是Spark自身的一个调度系统。对集群性能要求非常高时用。国内很少使用
    3)Yarn：采用Hadoop的资源调度器。国内大量使用
    4)Mesos：国内很少使用

3.Spark常用端口号
    1)4040	spark-shell任务端口
    2)7077	内部通讯端口，类比Hadoop的8020/9000
    3)8080	查看任务执行情况端口	类比Hadoop的8088
    4)18080	历史服务器	类比Hadoop的19888
	注意：由于Spark只负责计算，所以并没有Hadoop中存储数据的端口5
```



### Spark算子

```scala
transformation算子
1)单Value
	(1)map
	(2)mapPatition
	(3)mapPartitionWithIndex
	(4)flatMap
	(5)glom
	(6)groupBy
	(7)filter
	(8)sample
	(9)distinct
	(10)coalesce
	(11)repartition
	(12)sortBy
	(13)pipe
2)双Value
	(1)intersection
	(2)union
	(3)subtract
	(4)zip
3)Key-Value
	(1)partitionBy
	(2)reduceByKey
	(3)groupByKey
	(4)aggregateByKey
	(5)foldByKey
	(6)combineByKey
	(7)sortByKey
	(8)mapValues
	(9)join
	(10)cogroup

2)action算子
	(1)reduce
	(2)collect
	(3)count
	(4)frist
	(5)take
	(6)takeOrdered
	(7)aggregate
	(8)fold
	(9)countByKey
	(10)save
	(11)foreach
```



### spark的yarn-job提交(cluster)

```
1. 客户端向yarn的RM申请AM，同时在自身的sparkContext中创建DAGScheduler和TaskScheduler(创建driver)
2. 按照正常Yarn的流程，一个NM领取到AM任务作为AM与客户端的driver产生连接(在yarn-cluster中该AM直接作为Driver而不是连接Driver)
3. Driver根据任务信息通过AM向RM申请资源(计算容器)
4. AM通知领取到任务的NM向Driver的sparkContext反向注册并申请Task
5. driver的sparkContext分配Task给各个计算节点，并随时掌握各个任务运行状况。
6. 应用程序运行完成后，sparkContext向RM申请并注销关闭自己
```

 

### 如果使用Spark实现TopN的获取(描述思路或使用伪代码)

```
方法一：
（1）按照key对数据进行聚合(groupByKey)
（2）将value转换为数组，利用scala的sortBy或者sortWith进行排序(mapValues)数据量太大会OOM

方法二：
（1）取出所有的key
（2）对key进行迭代，每次取出一个key利用Spark的排序算子进行排序

方法三：
（1）自定义分区器，按照key进行分区，使用不同的key进到不同的分区。
（2）对每个分区运用spark的排序算子进行排序
```

### spark数据倾斜处理小结

| 方案                          | 简述                                                 | 使用场景                                                     |
| ----------------------------- | ---------------------------------------------------- | ------------------------------------------------------------ |
| hiveETL预处理                 |                                                      |                                                              |
| 过滤少数导致数据倾斜的key     |                                                      |                                                              |
| 提高shuffle操作的并行度       | 提高shuffle类算子的并行度，治标不治本                | 必须要对数据倾斜时，优先使用这种方案最简单                   |
| 两阶段聚合                    | 第一次打随机前缀再聚合，第二次去掉随机前缀再全局聚合 | 对RDD执行reduceByKey等聚合类shuffle算子或者在SparkSQL中使用group by语句进行分组聚合时 |
| 将reduce join转为map join     | 小表广播到大表所在executor进行map-join               | 在对RDD使用join类操作，或者是在SparkSQL中使用join语句时，而且join操作中的一个RDD或者表的数据量比较小（比如一几百M或者一两个G） |
| 采样倾斜的key并拆分join操作   |                                                      |                                                              |
| 使用随机前缀和扩容RDD进行join |                                                      |                                                              |



## 数据倾斜

```markdown
## 数据倾斜的表现
1)Hadoop中的数据倾斜表现：
* 有一个或多个Reduce卡住，卡在99.99%，一直不能结束。
* 各种container报错OOM。
* 异常的Reduce读写的数据量极大，至少远远超过其他正常的Reducer
* 伴随着数据倾斜，会出现任务呗被kill等各种诡异的表现。

2)hive中的数据倾斜
* 一般都发生在Sql中group by和join on上，而且和数据逻辑绑定比较深。

3)Spark的数据倾斜
Spark中的数据倾斜包括Spark Streming和Spark SQL。主要表现有下面几种：
* Executor lost，OOM。Shuffle过程出错；
* Driver OOM；
* 单个Executor执行时间特别久，整体任务卡在某个阶段不能结束；
* 正常运行的任务突然失败。

## 数据倾斜产生的原因
以Spark和Hive的使用场景为例。
它们在做数据运算的时候会涉及到，count distinct、group by、join on等操作，这些都会触发Shuffle动作，一旦触发Shuffle，所有相同key的值就会被拉到一个或多个Reducer节点上，容易发生单点计算问题，导致数据倾斜。
一般来说数据倾斜原因有以下几个方面。
1) key分布不均匀
2) 建表时考虑步骤
3) 业务数据激增

## 解决数据倾斜思路
很多数据倾斜的问题，都可以用和平台无关的方式解决，比如更好的数据预处理，异常值的过滤等。因此，解决数据倾斜的重点在于对数据设计和业务的理解，这两点搞清楚了，数据倾斜就解决了大部分。
1) 业务逻辑
2) 程序层面
3) 调参方面
4) 从业务和数据上解决数据倾斜
	很多数据倾斜都是在数据的使用上造成的。我们举几个场景，并分别给出它们的解决方案。
	* 有损的方法：找到异常数据，比如ip为0的数据，过滤掉。
	* 无损的方法：对分布不均匀的数据，单独计算。
	* 先对key做一层hash，先将数据随机打散让它的并行度变大，在汇集。
	* 数据预处理
```



## Flink

### 简单介绍一下Flink

```
Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。并且Flink提供了数据分布、容错机制以及资源管理等核心功能。Flink提供了诸多高抽象层的API以便用户编写分布式任务

DataSet API，对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便的使用Flink提供的各种操作符对分布式数据集进行处理，支持Java、Scala和Python。
DataStream API，对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持Java和Scala。
Table API，对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类SQL的DSL对关系表进行各种查询操作，支持Java和Scala

此外，Flink还针对特定的应用领域提供了领域库，例如：Flink ML，Flink的机器学习库。提供了机器学习Pipeline API并实现了多种机器学习算法。Gelly，Flink的图计算库，提供了图计算的相关API及多种图计算算法实现。
```

### Flink相比于Spark而言还有诸多明显优势

```
1.支持高效容错的状态管理，保证在任何时间都能计算出正确的结；
2.同时支持高吞吐、低延迟、高性能的分布式流式数据处理框架；
3.支持事假时间(Event Time)概念，事件即使无序到达甚至延迟到达，数据流都能够计算出精确的结果；
4.轻量级分布式快照(Snapshot)实现的容错，能将计算过程分布到单台并行节点进行处理。
```





### Flink和SparkStreaming的区别

```scala
Flink是标准的实时处理引擎，基于事件驱动。而Spark Streaming是微批(Micro-Batch)的模型

主要区别：
1)架构模型
    Spark Streaming在运行时的主要角色包括：Master、Worker、Driver、Executor。
    Flink在运行时主要包含：Jobmanager、Taskmanager和Slot
2)任务调度
    Spark Streaming连续不断的生成微小的数据批次，构建有向无环图DAG，Spark Streaming会依次创建DStreamGraph、JobGenerator、JobScheduler。
    Flink根据用户提交的代码生成StreamGraph，经过优化生成JobGraph，然后交给JobManager进行处理，JobManager会根据JobGraph生成ExecutionGraph，ExecutionGraph是Flink调度最核心的数据结构，JobManager根据ExecutionGraph对Job进行调度。
3)时间机制
	Spark Streaming支持的时间机制有限，只支持处理时间。
	Flink支持流处理查询在时间上的三个语义：处理时间，事件时间，注入时间。同时也支持watermark机制来处理滞后数据。
4)容错机制
	对于Spark Streaming任务，我们可以设置checkpoint，然后假如发生故障并重启，我们可以从上次checkpoint之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到敲好一次处理语义
	Flink则使用两阶段提交协议来解决这个问题。
```

### Flink的三种时间语义

```
Event Time：事件创建时间。它通常由事件中的时间戳描述，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问时间时间戳。
Ingestion Time：是数据进入Flink的时间。
Processing Time：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Ti	·1me
```



### 说一下Flink状态机制

```
Flink在做计算的过程中需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和checkpoint交互。
Flink提供了三种状态方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend
```

### Flink中的Watermark机制

```
Watermark是一种衡量Event Time进展的机制，可以设定延迟触发
Watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用Watermark机制结合window来实现。
数据流中的Watermark用于表示timestamp小于Watermark的数据，都已经到达了，因此，window的执行也是由Watermark触发的。


Watermark是Flink为了处理EventTime窗口计算提出的一种机制，本质上是一种时间戳，Watermark经常和window一起被用来处理乱序事件。
通过对数据源的分析，得出一个大致的数据是否乱序(可决定使用升序还是乱序的watermark)、乱序程度(可设置几秒延迟时间)
```

### Flink的CEP机制

```
CEP全称Complex Event Procssing，复杂事件处理
Flink CEP是在Flink中实现的复杂事件处理(CEP)库
CEP允许在无休止的事件流中检测事件模式，让我们有机会掌握数据中重要的部分。
一个或多个由简单事件构成的事件流通过一定的规则匹配，然后输出用户想得到的数据————满足规则的复杂事件
```



## 精准一次消费

```markdown
## SparkStreaming
Spark Streaming第一次运行不丢失数据
1. kafka参数auto.offset.reset参数设置成earliest从最初开始消费数据
Spark Streaming精准一次消费
1. 手动维护偏移量
2. 处理完业务数据后，再进行提交偏移量操作。
极端情况下，如在提交偏移量时断网或停电会造成spark程序第二次启动时重复消费问题，所以在涉及到金额或精确性非常高的场景会使用事务保证精准一次消费.



## Flink
下级存储支持事务：Flink可以通过实现两阶段提交和状态保存来实现端到端的一致性语义，分为以下几个步骤：
1)开始事务(beginTransaction)创建一个临时文件夹，来写把数据写入到这个文件夹里面。
2)预提交(preCommit)将内存中缓存的数据写入文件并关闭
3)正式提交(commit)将之前写完的临时文件放入目标目录下，这代表着最终的数据会有一些延迟。
4)丢弃(abort)丢弃临时文件
5)若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。
下级存储不支持事务：
具体实现时幂等写入，需要下级存储具有幂等性写入特性。



```



## 离线数仓

```markdown
## 数据来源
日志数据：前端埋点产生的用户行为的数据，主要有用户的登录、浏览、收藏、评论等。
业务数据：JavaEE后台数据中存储的业务流程中产生的注册、下单、支付、退单等相关的数据

## 数仓建模
数仓分层的好处：
	1）把复杂问题简单化
	2）减少重复开发
	3）隔离原始数据

### ODS层
原始数据层，将采集的数据原封不动导入，保持数据原貌！
分区表！按照日期进行分区！
日志相关的表：商品列表、商品点击、商品详情、广告、故障、后台活跃、通知、启动、点赞、评论、收藏等。
业务数据相关的表：订单表、用户表、支付流水表、订单详情表、商品表、三级、二级、一级、优惠券领用表、地区表。


```









## Flink实时数仓项目

FlinkCDC

```
什么是CDC？
CDC是Change Data Capture(变更数据获取)，捕获数据库当中的变化
核心思想：监测并获取数据库的变动(包括数据或数据表的插入、更新以及删除)

CDC主要分为基于查询和基于Binlog两种方式
				基于查询的CDC				基于Binlog的CDC
				Sqoop、KafkaJDBC Source		Canal、MaxWell、FlinkCDC
是否可以捕获所有数据变化	否						是
延迟性					高延迟						低延迟
是否增加数据库压力		是							否

FlinkCDC可以直接从MySQL、PostgreSQL等数据库直接读取全量数据和增量变更数据的source组件

1.获取执行环境
2.DDL方式建表
3.查询数据
4.将动态表转换为流
5.启动任务
    
    DataStream:
		优点：多库多表
        缺点：需要自定义反序列化器(灵活)
           
    FlinkSQL:
        优点：不需要自定义反序列化器
        缺点：单表查询
            
断点续传——————Checkpoint(HDFS)
```

每层的职能

```
ODS层：原始数据，日志和业务数据(Kafka)										
DWD层：根据数据对象进行单位分流，比如：订单、页面访问等等(Kafka)
DIM层：维度数据(HBase)
DWM层：对于部分数据对象进行一步加工，比如独立访问，跳出行为。依旧是明细数据层(Kafka)
DWS层：根据某个维度主题将多个事实数据轻度聚合，形成主题宽表(clickHouse)
```





```markdown

DWM层：
计算跳出行为的思路：
首先要识别哪些是跳出行为，要把这些跳出的访客最后一个访问的页面识别出来。那么要抓住几个特征
1.该页面是用户近期访问的第一个页面
	这个可以通过该页面是否有上一个页面(last_page_id)来判断，如果这个表示为空，就说明这是这个访客这次访问的第一个页面。
2.首次访问之后很长一段时间(自己设定)，用户没有继续再有其他页面的访问。
	这第一个特征的识别很简单，保留last_page_id为空的就可以了。但是第二个访问的判断，其实有点麻烦，首先这不是用一条数据就能得出结论的，需要组合判断，要用一条存在的数据和不存在的数据进行组合判断。而且要通过一个不存在的数据求得一条存在的数据。更麻烦的是他并不是永远不存在，而是在一定时间范围内不存在。那么如何识别有一定失效的组合行为呢？
	最简单的办法就是Flink自带的CEP技术。这个CEP非常适合通过多条数据组合来识别某个事件。
	用户跳出事件，本质上就是一个条件事件加一个超时事件的组合。
	
通过Flink的CEP完成跳出判断
1.设置时间语义为事件时间并指定数据中的ts字段为事件时间。
	由于这里涉及到时间的判断，所以必须设定数据流的EventTime和水位线。这里没有设置延迟时间，实际生产情况可以视乱序情况增加一些延迟。
	增加延迟forMonotonousTimetamps换成forBoundedOutOfOrderness即可。
	

DWM——————订单宽表
订单是统计分析的重要的对象，围绕订单有很多的维度统计需求，比如用户、地区、商品、品类、品牌等等。为了之后统计计算更加方便，减少大表之间的关联，所以在实时计算过程中将围绕订单的相关数据整合成为一张订单的宽表。
由于在之前的操作我们以及把数据分析拆成了事实数据和维度数据，事实数据进入到kafka数据流(DWD层)中，维度数据进入hbase中长期保存，那么我们在DWM层中要把实时和维度数据进行整合关联在一起，形成宽表。那么这里要处理的有两种关联，事实数据和事实数据关联、事实数据和维度数据关联。
* 事实数据和事实数据关联，其实就是流与流之间的关联。
* 事实数据与维度数据关联，其实就是流计算中查询外部数据源。

# 订单和订单明细关联(双流join)
	在flink中的流join大体分为两种，一种是基于事件窗口的join(Time Windowed Join)，比如join、coGroup等。另一种是基于状态缓存的join(Temporal Table Join)，比如intervalJoin。
	这里选用intervalJoin，因为相比较窗口join，intervalJoin使用更简单，而且避免了应匹配的数据处于不同窗口的问题。intervalJoin目前只有一个问题，就是还不支持left join
	但是这里是订单主表与订单从表之间的关联不需要left join，所以intervalJoin是较好的选择。
	
维度关联实际上就是流中查询存储在hbase中的数据表。但是即使通过主键的方式查询，hbase速度的查询也是不及流之间的join。外部数据源的查询常常是流式计算的性能评级，所以咱们在这个基础上还有进行一定的优化。


+ 优化方式1：加入旁路缓存模式(cache-aside-pattern)
	我们在上面实现的功能中，直接查询的Hbase。外部数据源的查询常常是流式计算的性能瓶颈，所以我们需要在上面实现的基础上进行一定的优化。我们这里使用旁路缓存。
	旁路缓存模式是一种非常常见的按需分配缓存的模式。任何请求有限访问缓存，缓存命中，直接获得数据返回请求。如果未命中则查询数据库，同时吧结果写入缓存以备后续请求使用

1)这种缓存策略有几个注意点
	缓存要设过期时间，不然冷数据会常驻缓存浪费资源。
	要考虑维度数据是否会发生变化，如果发生变化要主动清除缓存。
2)缓存的选型
	一般有两种：堆缓存或者独立缓存服务(redis、memcache)
	* 堆缓存，从性能角度看更好，笔记访问数据路径更短，减少过程消耗。但是管理性差，其他进程无法维护缓存中的数据。
	* 独立缓存服务(Redis、memcache)本身性能也不错，不过会有创建连接、网络IO等消耗。但是考虑到数据如果会发生变化，那还是独立缓存服务管理想更强，而且如果数据量特别大，独立缓存更容易扩展。
	因为咱们的维度数据都是可变数据，所以这里还是采用Redis管理缓存。
	
+ 优化2：异步查询
	在Flink流处理过程中，经常需要和外部系统进行交互，用维度表补全事实表中的字段。例如：在电商场景中，需要一个商品的skuid去关联商品的一些属性，例如商品所属行业、商品的生产厂家、生产厂家的一些情况；在物流场景中，知道包裹id，需要去关联包裹的行业属性、发货信息、收货信息等等。
	默认情况下，在Flink的MapFunction中，单个并行只能用同步方式去交互：将请求发送到外部存储，IO阻塞，等待请求返回，然后继续发送下一个请求。这种同步交互的方式往往在网络等待上就耗费了大量时间。为了提高处理效率，可以增加MapFunction的并行读，但增加并行度就意味着更多的资源，并不是一种非常好的解决方式。
	Flink在1.2中引入AsyncI/O，在异步模式下，在IO操作异步化，单个并行可以连续发送多个请求，哪个请求先返回就先处理，从而在连续的请求间不需要阻塞式等待，大大提高了流处理效率。
	AsyncI/O是阿里巴巴贡献给社区的一个呼声非常高的特性，解决与外部系统交互是网络延迟成为了系统瓶颈的问题。
	
	异步查询实际上是把维表的查询操作托管给单独的线程池完成，这样不会因为某一个查询造成阻塞，单个并行可以连续发送多个请求，提高并发效率。
	这种方式特别针对涉及网络IO的操作，减少因为请求等待带来的消耗。
	
# 总结
DWM层部分的代码主要的责任，是通过计算把一种明细转变为另一种明细以应对后续的统计。
* 利用状态(state)进行去重操作。(需求：UV计算)
* 利用CEP可以针对一组数据进行筛选判断。(需求：跳出行为计算)
* 使用intervalJoin处理join
* 处理维度关联，并通过缓存和异步查询对其进行性能优化。
```



```
一、课程重点

	1.行为数据的采集框架：FlinkCDC	MaxWell	Canal

	2.关于业务数据采集：动态分流----实现在不停机的情况下能够自动检测到业务表的增加，然后动态的添加并采集到Kafka当中

	3.宽表的创建：事实表与事实表--多流join	多流union
	4.关联维表	优化：旁路缓存--异步IO。大大提高时效性。

二、课程特色
	1.新		Flink1.12.0
	2.全		全套资料（git）
	3.细		粘贴复制可运行

三、技术要求
	1.语言	JAVA
	2.框架	Hadoop	Kafka	HBase	Zookeeper	Redis


1、整理思路，对着代码敲
2、保留注释，对着注释敲
3、什么都不要，自己敲

1、整理思路，对着注释敲
2、什么都不要，自己敲

1、整理思路，自己敲


整理思路====>画流程图


数据采集
实时数仓的分层介绍
1.1普通实时计算与实时数仓比较


实时数仓分层介绍
ODS：原始数据，日志和业务数据。				kafka
DWD：根据数据对象为单位进行分流（测输出流），比如订单、页面访问等等。			
DIM：维度数据							HBase
DWM：对于部分数据对象进行进一步加工，比如独立访问、跳出行为，也可以和维度进行关联，形成宽表，依旧是明细数据层。		Kafka
DWS：根据某个主题将多个事实数据轻度聚合，形成主题宽表		ClickHouse
ADS：把ClickHouse中的数据根据可视化需进行筛选聚合		不落盘



离线计算-实时计算：需求的固定性
即席查询：需求的临时性
Presto：当场计算（基于内存速度快）
Kylin：预计算（提前算好），多维分析（Hive With Cube）


架构分析
离线
	Sqoop导入数据的方式
		全量：where 1=1
		增量：where 创建时间=当天
		新增及变化：where 创建时间=当天 or 操作时间=当天
		特殊：只导入一次
	Flume
		TailDirSource：
			优点：断点续传，监控多目录，实时监控
			缺点：当文件更名之后会重新读取该文件造成重复
			注意：
				1.要使用不更名打印日志框架（logback）
				2.修改源码，让TailDirSource判断文件时只看iNode值
			
		KafkaChannel：
			优点：将数据写入Kafka，省了一层sink
			Kafka：生产者、消费者
			用法：
				1.Source-KafkaChannel-Sink
				2.Source-KafkaChannel
				3.KafkaChannel-Sink
			
		逻辑线：数据流，监控，优化，配置。
		
	Kafka
		Producer：如何保证生产者不丢数据？
			ACK	0 1 -1
			拦截器，序列化器，分区器
			发送流程	sender main
			幂等性，事务
			分区规则 --> 
				有指定分区则发往指定分区
				没有指定分区，则根据Key值Hash
				没有指定分区也没有Key的时候，轮询（粘性）
		
		Broker
			Topic：
				副本：高可靠
					ISR：LEO、HW
				分区：高并发，负载均衡（防止热点）
			
		Consumer
			分区分配规则
			offset保存
				默认：__consumer_offset主题
				其他：手动维护Offset（Mysql）	保存数据&保存Offset写到一个事务
				精准一次消费
				先保存数据后保存offset	重复数据+幂等性(精准一次消费)
				先保存Offset后保存数据	丢失数据
				
			优化、监控、配置、数据量、峰值速度
			
		HQL是怎么翻译成MR的？
		4个器：解析器、编译器、优化器、执行器
		AST抽象语法树
		
		hive分层建模
		
		
实时
	MySQL --> Kafka
	Canal/MaxWell/FlinkCDC
	原理：监控binlog
	
	启动日志、动作日志、曝光日志、错误日志、页面日志
	
	ods：2个主题
			行为数据一个主题
			业务数据一个主题
			
	dwd：
		用Flink将Kafka的ODS层的数据消费。采用侧输出流进行分流分到Kafka的不同主题里
		同时对于业务数据而言，除了一部分要放到Kafka的DWD事实表。另外一部分要放到Hbase(维表数据DIM层)
		
	dwm：
		用Flink去消费dwd的主题数据，然后中间可能会关联维表数据（访问HBase的数据）形成DWM层
	
	dws：
		用Flink去消费dwd和dws写入到ClickHouse
		
		
	对接数据接口做可视化展示
				
			


	离线架构
		优点：耦合性低，稳定性高
		缺点：时效性差一点
		说明：
			1.项目经理(架构师)是大公司出来的。追求系统的稳定性
			2.耦合性低，稳定性高
			3.考虑到公司的未来的发展，数据量一定会变的很大
			4.早期的时候实时业务是使用SparkStreaming(微批次)
		
		
	实时架构
		优点：时效性好
		缺点：耦合性高，稳定性低
		
		用日志服务器直接对接Kafka，耦合性高，不考虑系统的安全
		说明：
			1.时效性好 Flink
			2.Kafka集群高可用，挂一台两台是没有问题的
			3.数据量小，所有机器存在于同一个机房，传输没有问题
			4.架构还是公司项目经理（架构师）定的
			

FlinkCDC
	什么是CDC？
	CDC是Change Data Capture(变更数据获取)，捕获数据库当中的变化
	核心思想：监测并获取数据库的变动（包括数据或数据表的插入、更新以及删除）
	
	CDC主要分为基于查询和基于Binlog两种方式
					基于查询的CDC				基于Binlog的CDC
				Sqoop、KafkaJDBC Source 	Canal、MaxWell、DEbezium
	是否可以捕获所有数据变化	否				是
	延迟性					高延迟				低延迟
	是否增加数据库压力			是				否 
	
	
FlinkCDC可以直接从MySQL、PostgreSQL等数据库直接读取全量数据和增量变更数据的source组件	
	
	
=============业务数据采集=============
FlinkCDC:
			DataStream:
				优点:多库多表
				缺点:需要自定义反序列化器(灵活)
			FlinkSQL:
				优点:不需要自定义反序列化器
				缺点:单表查询
				
断点续传----Checkpoint

	
MaxWell
实时读取MySQL二进制日志Binlog，生成JSON格式的消息，作为生产者发送给Kafka
断点续传----Mysql

Canal
断点续传----依赖于本地磁盘mate.dat


			FlinkCDC		MaxWell		Canal
断点续传	checkpoint		MySQL		本地磁盘		
			
SQL->数据 	无				无			一对一(炸开)
初始化功能	有(多库多表)	有(单表)	无(单独查询)
封装格式	自定义			JSON		JSON(c/s自定义)
高可用		运行集群高可用	无			集群(ZK)





ODS -> DWD
行为数据DWD
重点（业务数据DWD）

分层需求分析：
	行为数据拆分到DWD中
	业务数据：事实表放到DWD层（Kafka）
			  维度表放到DIM层（HBase）
		
每层的职能：		

	分层：数据描述																		生成计算工具			存储媒介
	ODS层：原始数据，日志和业务数据。													FlinkCDC/日志服务器		Kafka
	DWD层：根据数据对象进行单位分流，比如：订单、页面访问等等。							Flink					Kafka
	DIM层：维度数据																		Flink					HBase
	DWM层：对于部分数据对象进行进一步加工，比如独立访问，跳出行为。依旧是明细数据层。	Flink					Kafka
	DWS层：根据某个维度主题将多个事实数据轻度聚合，形成主题宽表							Flink					ClickHouse





================DWD================
主要任务：

从Kafka的ODS层读取的日志数据分3类，页面日志、启动日志、曝光日志。
页面日志输出到主流，启动日志输出到启动侧输出流，曝光日志侧输出流。
将不同流的数据推送到下游的Kafka的不同的Topic中
	1、识别新老用户 is_new	状态编程
	ProcessFunction实现分流


业务数据：
事实表(Kafka)、维度表(HBase)
动态分流：
	在实时计算中一般把维度数据写入存储容器，一般是方便通过主键查询的数据库。比如HBase、Redis、MySQL
				一般把事实数据写入流中，进一步处理，最终形成宽表.
				
				不用Redis、MySQL的原因：
					维度数据当中用户维度数据量大。（代码搞复杂，所以全放HBase）
					JavaEE也在使用MySQL。并发压力大。
					
					三种方案：
						1、用Zookeeper存储，通过Watch感知数据变化
						2、另一种是用MySQL数据库存储，周期性的同步。
						3、使用MySQL数据库存储，使用广播流。
				
				table_process字段
					sourceTable		type	sinkType	sinkTable			sinkColums		pk(主键)	extend
					base_trademark	insert	hbase		dim_xxx(表名)
					order_info		insert	Kafka		dwd_xxa(主题名)
					order_info		update	Kafka		dwd_xxb(主题名)
					
				广播流：
					1.解析数据：String => TableProcess
					2.检查HBase表是否存在并建表！
					3.写入状态
				主流：
					1.读取状态
					2.过滤字段
					3.分流
				
ODS：
	数据源：行为数据，业务数据
	架构分析：
	FlinkCDC：
		DataStream/FlinkCDC
		FlinkCDC/MaxWell/Canal
	保持数据原貌，不做任何修改！
	ods_base_log,ods_base_db
	
	
DWD-DIM：
	行为数据：DWD(Kafka)
		1.过滤脏数据-->测输出流	脏数据率
		2.新老用户校验-->前台校验不准
		3.分流-->侧输出流	页面、启动、曝光、动作、错误
		4.写入Kafka
		
	业务数据：DWD(Kafka)-DIM(Phoenix)
		1.过滤数据 --> 删除数据
		2.读取配置表创建广播流
		3.连接主流和广播流并处理
			1)广播流数据：
				a.解析数据
				b.Phoenix建表
				c.写入状态广播
			2)主流数据：
				a.读取状态
				b.过滤字段
				c.分流(添加SInkTable字段)
		4.提取Kafka和HBase流分别对应的位置
		5.Hbase流：自定义Sink
		6.Kafka流：自定义序列化方式


===============DWM层与DWS层的设计===========
ODS(保持数据原貌，不做任何修改)			DWD/DIM		和业务需求不大
DWS/DWT									DWM/DWS		业务相关
					ADS								= 需求


由DWS决定DWM的表怎么建		DWS层来自维度(维度建模)
ADS：指标


实时数仓为什么没有DWT？
	DWT是历史的聚集。是个累积的结果实时数仓不需要
	
uv(DAU)日活
	需要page_log过滤去重。			DWM


UV(Unique Visitor)即独立访客。在实时计算中，也可以称为DAU(Daily Active User)即每日活跃用户，因为在实时计算中的UV通常是指当日访客数
如何从用户行为日志中识别出当日的访客，那么有两点：
	1.是识别出该访客打开的第一个页面，表示这个访客开始进入我们的应用
	2.由于访客可以在一天中多次进入应用，所以我们要在一天的范围内进行去重

				key的键控状态
	KeydState	mid -> State（日期）
	
	取出上一跳
	lastpage_id 	null
					不等于null		判断状态时间是否相等：	相等 ×
															不相等√		对状态进行更新
```



## 大数据面试吹牛草稿

```markdown
各位面试官好！
	我叫xxx，毕业于xxx，之前在xxx公司待了一年多，期间一直从事的是IT行业，刚开始的时候做的是Java开发后来转岗到大数据方向做大数据开发；刚转行到大数据开发时开始比较困难的，大数据并不像java那样一套框架基本可以搞定所有的问题，而是不同的业务对于同一个问题有多重解决方案。
	
	


## 简要介绍项目
接下来我先介绍一下这个项目：
项目是一个高度定制化的商城平台，最近主要做的是数仓和离线指标计算这一块；
### 数仓初期
数仓搭建初期，由于公司数据量少，经验不足，数仓没有层级概念，过来的数据直接进行解析，每次计算一个指标的时候，都需要进行ETL操作，每次都需要进行join，造成了大量的重复操作，效率十分低下，浪费大量人力。
### 数仓后期
数仓在搭建一段时间后，重复的计算操作困恼了我很久，后来我参考了阿里的离线数仓架构，我们对数仓进行了重新的架构构建，对数仓进行了分层规划。
主要分为：
1.ods层
2.dwd层
3.dws层
4.ads层
分四层的原因主要是为了隔离数据然后还能复用上一层计算出来的数据，另一方面也是为了数据备份；


## 介绍熟悉的框架
数仓采集我们主要是采集业务系统的数据及日志数据两部分，业务系统数据存储在Mysql中，使用Sqoop将数据导入大数据平台。

Sqoop：
Sqoop是在Hadoop生态体系和RDBMS体系之间传送数据的一种工具。它的工作机制是将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。
我们在使用Sqoop导入导出时出现了Null的存储一致性问题，
Hive中的Null在底层是以'\N'来存储，而MySQL中的Null在底层就是Null。为了保障数据两端的一致性，在导出数据时采用--input-null-string和--input-null-non-string两个参数。导入数据时采用--null-string和--null-non-string。

Flume：
对于日志采集我们当时选用的是Flume，采集日志框架也有很多，之所以选择Flume主要是因为它采集数据的效果比较好，其次是对于HDFS和Kafka支持的也比较好。


Kafka：
* 为什么选择Kafka作为消息队列来处理数据
当时在做技术选型的时候我们也是做了大量的调研，因为消息队列的产品有很多比如：ReactMQ Kafka等；
我们当时调研考虑的主要指标就是吞吐量这一块，因为大数据流式处理对数据的吞吐量要求是非常高的，在这一块ReactMQ是比较厉害的，吞吐量可以达到1w多每秒；通过后来的调研以后发现kafka的吞吐量比ReactMQ更高，如果使用恰当的话吞吐量甚至可以达到10w+每秒

kafka支持消息持久化，消费端是主动拉取数据，消费状态和订阅关系由客户端负责维护，消息消费完后，不会立即删除，会保留历史消息。因此支持多订阅时，消息只会存储一份就可以。
1.broker：kafka集群中包含一个或多个服务实例(节点)，这种服务实例被称为broker(一个broker就是一个节点/一个服务器)；
2.topic：每条发布到kafka集群的消息都属于某个类别，这个类别就叫topic；
3.partition：partition是一个物理上的概念，每个topic包含一个或者多个partition；
4.producer：消息的生产者，负责发布消息到kafka的broker中；
5.consumer：消息的消费者，向kafka的broker中读取消息的客户端；


```























```sh
1. 自我介绍？
2. 你是怎么接触的大数据？
3. 你们的数仓模型是什么样的？
4. 星型模式、雪花模型、星座模型各有什么好处？
5. 数仓分层架构的设计及每一层干什么的？
6. 你们数仓中拉链表怎么设置的？
7. 你们拉链表有分区吗？拉链表分区是怎么控制的？（我说的是每天全量刷新，他接着问如果你们数据量特别大呢？怎么解决的？）
8. 事实表有哪些？事实表中的历史数据怎么修改？（这个没答上来，面试官说你们没有做过快照表吗？这个没听说过）
9. 你们工作中实际的工作流程是怎么样的？
10. 如果给你提一个需求，需要将ods、dwd、dws层数据全部都要用到，并且需要全部都要重新在做一遍，然后为了生成这个ads层数据的结果，你是怎么避免这种烟囱式式开发的？（这个我没太懂意思，然后说的没遇到过）
11. 你们元数据管理怎么做的？
12. 你们数仓部门几个人？
13. 你们集群是什么规模？每台服务器什么配置？
14. 数仓中用的存储格式是什么？ORC和Parquet一般是什么场景下用？
15. Hive中的UDF和UDTF？
16. 开窗函数的介绍？排序的函数？
17. Sort by和Order by的区别？
18. 行转列和列转行用的哪些函数？
19. Hive中Join的工作原理？
20. mapJoin的工作原理？
21. 你们工作中Azkaban怎么实现的跨工作流？比如说ads层的一个指标需要依赖于一个宽表，肯定不在一个工作流中，你们是怎么处理这种情况的？
22. 工作中如果做一个指标需要依赖于别人开发设计好的一张宽表，这种场景你们是怎么处理的？
23. 你为什么要离职？
24. 你是主动提出离职的还是公司不给你续签合同了？
25. 你们公司在哪个地方？
26. 你住在哪个地方？去公司要多久时间？
27. 数仓怎么搭建起来的？
28. 你们数仓怎么建模型的？怎么分层的？
29. 如果要让你设计一个模型的话，你会怎么设计？（可以随便举个例子来说）
30. 指标分析你们主要是用的什么？
31. 谈谈你对Hive的优化以及写SQL过程中的优化？
32. Select * 与Select 写全部列名  这两个有什么区别吗？
33. 一个SQL题：如何去求这一天24小时每隔5分钟的股票的一个峰值和低估值？（不是实时的，数据可以是昨天一天的数据）
34. 你有什么问我的吗？
```























```
：盒马鲜生app实时分析系统
项目简介：盒马鲜生app每天会产生大量的用户行为日志和业务数据,为了让这些数据的处理更加及时，从而能更好的做出决策，该项目从之前的秒级处理，到现在毫秒级处理，提升巨大，使用的技术为当下最火热的flink技术。
项目架构：nginx+springboot+mysql+flinkCDC+flink+kafka+hdfs+hbase+redis+clickhouse 
项目周期：2020.9-2021.9
项目职责：
1.	数据采集：用户行为数据和业务数据通过nginx+springboot 将数据发送到指定主题。 
2.	用户行为日志处理：在行为日志中由于服务器的重启可能导致，某些用户之前时老访客，结果成为了新访客，所以需要进行状态修复，flink中的键控状态可以解决，首先将数据按照手机id进行分组，键控状态会记录相同key的时间数据状态，修复时根据时间进行新老状态修复。
3.	业务数据处理：由于业务数据种类很多，需要发送到不同的主题，对于事实表的数据要发送到对应的主题，而对应的维度表数据要存储到hbase，再进行维表关联的时候进行读取，当前采用的技术为动态分流，我创建一张配置表，里面记录了什么类型的信息应该发送的什么主题或者插入到hbase，这样大大减少了不必要的代码。如果是插入hbase，则需要判断表是否存在，不存在就创建，如果是kafka，则直接发送。再后面的业务数据需要和维表数据进行关联，所以我加入了旁路缓存，该缓存用于记录访问过的维表信息，下次访问时直接从redis读取，为防止冷数据的产生，设置了过期时间，修改某个维表的某条数据时会从redis删除该数据，下次从hbase读取又能跟新到redis中。再关联维表数据时，需要从hbase频繁读取数据，如果时传统的sync/io，只能一条一条的读取，效率低下，而使用flink的异步io可以同时多次读取，效率大大提高。



v	项目名称：盒马鲜生app准实时分析系统
项目简介：由于app产生的海量数据里有部分数据有时效性，一旦超过某个时间，数据就会失去价值，我们无法进行离线处理，在交易系统中，每一条数据都很关键，所以需要进行实时处理，在允许秒级延时的基础上，使用SparkStreaming 进行开发。 
技术架构：nginx +mysql+kafka+redis+maxwell+SparkStreaming+hbase +kibana+ elasticsearch+clickhouse
项目周期：2019.9-2020.9
项目职责：
1.	数据拉取：app产生的用户行为日志通过nginx和springboot发送到kafka的指定主题， 业务数据会直接存到mysql里面，通过maxwell将新插入的数据发送到kafka的指定主题
2.	用户行为数据处理:通过sparkstreaming程序消费页面的行为日志数据，为了实现精准一次消费，使用redis存放偏移量，每次运行从redis读取最新的偏移量，然后成功结束就将当前最新的偏移量写入，
因为流是一直运行的，所有会一直重复进行偏移量的读写，然后通过redis根据设备id进行去重，用于统计app每天的日活，结果放到elasticsearch进行存储。
3.	业务数据处理:sparkStreaming程序消费maxwell发送到kafka的数据，对该数据进行首单分析，例如，当天的首单人数在不同省份的分布情况，以及男女比例。该状态根据首单人数不断进行跟新。该程序也需要实现精准一次消费，某用户的首单应该永久保存和用户数量可能很大，所以存储在HBASE，每消费到一批数据，就从HBASE中取出下过首单的用户id,对首单和非首单进行不同的状态标记，由于同一批次中可能出现下了多次首单的情况，所以需要对首单进行状态修正,首先将订单按照用户分组，同组内的订单按照时间排序，将第一个订单置为首单，其他为非首单，然后将状态写入hbase保存。由于订单主题没有维表信息，所以需要进行维度关联。




v	项目名称：盒马鲜生app用户画像系统
项目简介：结合app每日产生的业务数据和用户行为日志数据等多种数据来源，使用Spark技术开发的大数据统计分析平台，对商城的各种用户行为（访问行为、购物行为、广告点击行为等）进行分析。用统计分析出来的数据，辅助公司中的PM（产品经理）、数据分析师以及管理人员分析现有产品的情况，并根据用户行为分析结果持续改进产品的设计，以及调整公司的战略和业务。
技术架构：kafka+hdfs+hive+sparksql+presto+milvus+clickhouse 
项目周期：2019.1-2019.9
项目职责：
1. 数据采集：从盒马鲜生app离线分析系统中获取分析数据，可以使用Sparksql直接访问保存在HDFS中的业务数据，通过Azkaban定时任务定时将数据导入到数仓ODS层中。
2. 指标计算：
(1)	常规数据指标SQL的编写，例如：各个商品分类的销量TopN，用户复购率，分地域的订单量等等。
(2)	留存分析模型UDAF的编写，将留存查询转换为通过记录每个用户在每天的状态，实现retention函数。之后合并所有用户的状态值，实现retention_merge函数，得到每日留存数据。
(3)	漏斗分析模型UDAF的编写，通过将漏斗查询转化为对用户发生有序事件漏斗深度的计算，首先计算每个用户的漏斗深度，实现funnel函数，之后根据深度合并得到每次漏斗的人数，实现funnel_merge函数。




v	项目名称：盒马鲜生app离线分析系统
项目简介：盒马鲜生app每天会产生大量用户行为日志和业务日志，如果能从中挖掘出价值，就能为企业的决策，提供数据支持，从而改进业务流程，提高产品销量。
技术架构：flume+kafka+sqoop+mysql+hive+hdfs+hbase+kylin+superset+Azkaban+Zabbix+atlas+ranger
项目周期：2018.7-2019.1
项目职责：
1. 数据收集：盒马鲜生app每天都会有1000万左右的日活，其中会产生大量的用户行为日志和业务日志数据，我们将对Nginx服务器获取的用户行为日志数据落地到本地磁盘，通过flume写入到hdfs，将获取到的业务数据放到mysql进行存储，通过sqoop写入到hdfs.
2. 数据清洗：每天产生的用户行为日志中可能会出现一些错误数据，需要通过flume进行拦截，过滤掉错误日志，并将数据发送到kafka，进行削峰，然后flume进行采集，由于会出现零点漂移问题，所有再次拦截，进行时间修正，最后写到hdfs。
3. 数仓构建:首先构建ods层,将用户行为日志和业务日志对应的表创建，同时指定存储路径和存储格式，然后是dwd层，根据ods层的表的特点选择不同的同步策略进行同步，接下来是dws，将数据根据不同的主题进行预聚合，例如，统计盒马鲜生每天的销售额，接下来是dwt层，对dws的聚合结果再次聚合，例如，统计一个月或者一周内的销售额。最后是ads层，该层根据dws层的数据为实际业务需求进行统计数据，最后将ads层的数据存放到mysql,编写相应的接口进行可视化展示。
```









































